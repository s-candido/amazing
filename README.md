# ğŸ¦† DuckDB ETL - Analyse Comportementale Utilisateur (Projet Amazing)

Ce projet est un pipeline de traitement de logs utilisateurs pour le marketplace **Amazing**, permettant de transformer des fichiers `.csv` en **features utilisateurs** exploitables pour du clustering ou de la segmentation comportementale.

---

## ğŸ§± Architecture du projet

### ğŸ“ DonnÃ©es d'entrÃ©e
Des fichiers CSV contenant les Ã©vÃ©nements utilisateur :

- Colonnes all_events : `event_time`, `event_type`, `product_id`, `category_code`, `price`, `user_id`, `user_session`
- Colonnes user_segments : `user_id`, `total_events`, `total_views`, `total_purchases`, `avg_time_between_events`, `total_spent`, `avg_basket`, `last_event_time`, `conversion_rate`, `purchase_ratio`, `days_since_last_event`, `segment`

### ğŸ—ƒï¸ Base DuckDB locale
- Fichier gÃ©nÃ©rÃ© : `amazing.duckdb`
- Tables principales :
  - `all_events` : tous les logs concatÃ©nÃ©s
  - `loaded_files` : suivi des fichiers dÃ©jÃ  importÃ©s
  - `user_segments` : rÃ©sultats du clustering utilisateur

---

## âš™ï¸ FonctionnalitÃ©s

- âœ… Chargement automatique des fichiers `.csv` depuis le dossier `./data`
- âœ… Ingestion dans DuckDB avec vÃ©rification anti-doublons
- âœ… AgrÃ©gation des Ã©vÃ©nements utilisateur :
  - Nombre d'Ã©vÃ©nements, vues, achats
  - Total dÃ©pensÃ©, panier moyen, taux de conversion
  - RÃ©cence, dÃ©lai moyen entre interactions
- âœ… Filtrage des utilisateurs avec **â‰¥ 10 Ã©vÃ©nements**
- âœ… Traitement par batch pour efficacitÃ© mÃ©moire
- âœ… Clustering des utilisateurs (`KMeans`)
- âœ… RÃ©duction de dimension (`PCA`) + Visualisation 2D
- âœ… Export des rÃ©sultats dans la table `user_segments`

---

## ğŸ“Š Exemple de `user_features`

| user_id | segment | total_events | avg_basket | conversion_rate | days_since_last_event |
|---------|---------|---------------|-------------|------------------|------------------------|
| 123456  | 0       | 25            | 55.30       | 0.08             | 2                      |
| 987654  | 1       | 12            | 0.00        | 0.00             | 14                     |
| 333111  | 2       | 48            | 102.90      | 0.20             | 5                      |

---

## ğŸš€ Utilisation

### 1. CrÃ©er le dossier `data/` (sâ€™il nâ€™existe pas dÃ©jÃ )

```bash
mkdir data
```

Place dans ce dossier les fichiers `.csv` Ã  importer (`2019-Oct.csv`, etc.)

### 2. Lancer le script

> ğŸ•’ **Note importante** :  
> Le **premier chargement peut Ãªtre trÃ¨s long** (plusieurs dizaines de minutes) si les fichiers contiennent des millions de lignes.  
> Ensuite, le script dÃ©tecte automatiquement les fichiers dÃ©jÃ  importÃ©s grÃ¢ce Ã  la table `loaded_files`.

### 3. Lancer le script de clustering

Cela calcule les statistiques utilisateur, filtre les profils actifs, applique KMeans et exporte les rÃ©sultats dans user_segments.
Une visualisation des clusters est gÃ©nÃ©rÃ©e automatiquement.

---

## ğŸ” RequÃªtes utiles

### Utilisateurs par segment

```sql
SELECT segment, COUNT(*) FROM user_segments GROUP BY segment;
```

### Utilisateurs rÃ©cents

```sql
SELECT * FROM user_segments WHERE days_since_last_event < 7;
```


---

## ğŸ‘¤ Auteurs

Projet MSPR Bloc 2 â€“ Ã‰tudiants ECDPIA  
Powered by ğŸ¦† DuckDB, ğŸ’¡ Pandas, ğŸ¤– Scikit-learn
